[train] #train parameters
epoch = 30
fp16 = False
batch_size = 6
no_valid = False
reader_num = 30

optimizer = adamw
learning_rate = 1e-5
weight_decay = 0
step_size = 1
lr_multiplier = 1
rel_num = 97


[eval] #eval parameters
batch_size = 4
reader_num = 30


[data] #data parameters
train_dataset_type = Naive
train_formatter_type = FineTune
train_data_path = data/train_annotated.json
train_score_path = data/rank_result/

valid_dataset_type = Naive
valid_formatter_type = FineTune
valid_data_path = data/dev.json
valid_score_path = data/rank_result/

test_dataset_type = Naive
test_formatter_type = FineTune
test_data_path = data/test.json
test_score_path = data/rank_result/

label2id = data/label2id.json

[model] #model parameters
model_name = FineTune
max_len = 512
hidden_size = 256


[output] #output parameters
output_time = 1
test_time = 1

model_path = checkpoint
model_name = FineTune


accuracy_method = ConsGraph
output_function = ConsGraph
output_value = micro_precision,micro_recall,micro_f1,macro_f1

